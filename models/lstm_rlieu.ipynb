{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from model_team14 import select_features\n",
    "\n",
    "## select imputed & transformed data\n",
    "X=pd.read_csv('../data/X_data_tr.csv', index_col='date', parse_dates=True)\n",
    "y=pd.read_csv('../data/y_data_tr.csv', index_col='date', parse_dates=True)\n",
    "threshold=0.2\n",
    "criteria=None\n",
    "\n",
    "metadata=pd.read_csv('../data/full_info.csv')\n",
    "df_feature=select_features(metadata, X, threshold, criteria=criteria)\n",
    "\n",
    "selected_features=list(df_feature[df_feature.select==1]['variable'])\n",
    "\n",
    "def get_data(y_type, test_year, features):\n",
    "    X_train=X[features][:-(test_year*12)]\n",
    "    y_train=y[y_type][:-(test_year*12)]           \n",
    "    X_test=X[features][-(test_year*12):]   \n",
    "    y_test=y[y_type][-(test_year*12):]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy==1.23.5\n",
    "# !pip install protobuf==3.19.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install protobuf==3.19.0\n",
    "import tensorflow as tf\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import Recall, Precision  ##, F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)        \n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "# Timesteps will define how many Elements we have\n",
    "# TIME_STEPS = 5\n",
    "\n",
    "# X_train, y_train = create_dataset(X_train, y_train, TIME_STEPS)\n",
    "# X_test, y_test = create_dataset(X_test, y_test, TIME_STEPS)\n",
    "\n",
    "# print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tf.random.normal([510, 18, 12])\n",
    "# lstm = tf.keras.layers.LSTM(100)\n",
    "# output=lstm(inputs)\n",
    "# print(output.shape)\n",
    "# input=output\n",
    "# dense=tf.keras.layers.Dense(3, activation='softmax')  #\n",
    "# output=dense(input)\n",
    "\n",
    "# print(output.shape)\n",
    "# # np.array(output).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def grid_search(trainX, trainy, testX, testy, y_type, nl=[50,100], epochs=[100,300], batch_sizes=[10], time_steps=[18,24],\n",
    "                n_layer=[50,100]):\n",
    "    results = []\n",
    "    best_auc = 0\n",
    "    best_params = None\n",
    "    nc=len(trainy.unique())\n",
    "\n",
    "\n",
    "    for time_step in time_steps:\n",
    "        X_train, y_train = create_dataset(trainX, trainy, time_step)\n",
    "        X_test, y_test = create_dataset(testX, testy, time_step)\n",
    "        y_train = to_categorical(y_train, num_classes=nc)\n",
    "        y_test = to_categorical(y_test, num_classes=nc)\n",
    "        \n",
    "        loss_type = 'categorical_crossentropy'   ##if y_type == 'y_agg' else 'binary_crossentropy'\n",
    "\n",
    "    \n",
    "        for num_epochs in epochs:\n",
    "            for batch_size in batch_sizes:\n",
    "                for num_layer in nl:\n",
    "                    # create the model\n",
    "                    model = Sequential()\n",
    "                    model.add(LSTM(num_layer, input_shape=(X_train.shape[1], X_train.shape[2])))  ##input_shape=(X_train.shape[1], X_train.shape[2])\n",
    "                    # model.add(Dropout(0.2))\n",
    "                    #model.add(Dense(2))\n",
    "                    model.add(Dense(nc, activation='softmax'))\n",
    "\n",
    "                    model.compile(loss=loss_type, optimizer='adam', metrics=['AUC','Accuracy',\n",
    "                                                                             'Recall', \n",
    "                                                                             'Precision'])\n",
    "                    model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size)\n",
    "                    print(model.summary())\n",
    "\n",
    "                    # Final evaluation of the model\n",
    "                    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "                    #print(scores)\n",
    "                    auc = scores[1]*100\n",
    "                    acc = scores[2]*100\n",
    "                    recall = scores[3]*100\n",
    "                    precision = scores[4]*100\n",
    "                    #print(\"AUC: %.2f%%\" % (auc))\n",
    "\n",
    "                    current_result = {'model':model,\n",
    "                                      'time_steps': time_step,\n",
    "                                      'num_epochs': num_epochs,\n",
    "                                      'batch_size': batch_size,\n",
    "                                      'hiddenlayer': num_layer,\n",
    "                                      'auc': \"%.2f%%\" % (auc),\n",
    "                                      'acc': \"%.2f%%\" % (acc),\n",
    "                                      'recall': \"%.2f%%\" % (recall),\n",
    "                                      'precision': \"%.2f%%\" % (precision)\n",
    "                                    }\n",
    "                    results.append(current_result)\n",
    "\n",
    "                    if auc > best_auc:\n",
    "                        best_auc = auc\n",
    "                        best_params = current_result\n",
    "\n",
    "    print(\"Best AUC: \", best_params)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_type = 'y_agg'\n",
    "# X_train, y_train, X_test, y_test = get_data(y_type, 5, selected_features)\n",
    "\n",
    "# # print(grid_search(X_train, y_train, X_test, y_test, y_type, nl=[50,100],  epochs=[300,500], batch_sizes=[5], time_steps=[18,24]))\n",
    "# ## ,  epochs=[100,300], batch_sizes=[5,10], time_steps=[18,24]\n",
    "\n",
    "# result_dict_agg=grid_search(X_train, y_train, X_test, y_test, y_type, nl=[50,100],  epochs=[300,500], batch_sizes=[5], time_steps=[18,24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_type = 'y_oecd'\n",
    "# X_train, y_train, X_test, y_test = get_data(y_type, 5, selected_features)\n",
    "\n",
    "# # print(grid_search(X_train, y_train, X_test, y_test, y_type, nl=[10,20],  epochs=[5,10], batch_sizes=[5], time_steps=[18]))\n",
    "# ## ,  epochs=[100,300], batch_sizes=[5,10], time_steps=[18,24]\n",
    "\n",
    "# result_dict_oecd=grid_search(X_train, y_train, X_test, y_test, y_type, nl=[50,100],  epochs=[300,500], batch_sizes=[5], time_steps=[18,24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(result_dict_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(result_dict_oecd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model2=result_dict[1]['model']\n",
    "\n",
    "# print(model, model2)\n",
    "\n",
    "# dir(model)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall shap\n",
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('../result/result_dict_agg.pkl','wb') as f:\n",
    "#     pickle.dump(result_dict_agg, f)\n",
    "\n",
    "# with open('../result/result_dict_oecd.pkl','wb') as f:\n",
    "#     pickle.dump(result_dict_oecd, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall numba\n",
    "# #!pip install --upgrade numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shap\n",
    "# import model_team14 \n",
    "# from model_team14 import *  ##select_features, plot_pca, DTW\n",
    "\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "# from sklearn.metrics import confusion_matrix,accuracy_score, recall_score, precision_score, f1_score,classification_report \n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(np.array(X_test_shap))\n",
    "# model.fit(np.array(X_test_shap), np.array(y_train_shap))\n",
    "# model.summary()\n",
    "# X_train_shap.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-06-21 03:21:52         1822\n",
      "metadata.json                                  2023-06-21 03:21:52           64\n",
      "variables.h5                                   2023-06-21 03:21:52       185968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\lstm\n",
      "......vars\n",
      "...layers\\lstm\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...metrics\\auc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      ".........3\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\precision\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\recall\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-06-21 03:21:52         1823\n",
      "metadata.json                                  2023-06-21 03:21:52           64\n",
      "variables.h5                                   2023-06-21 03:21:52       578800\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\lstm\n",
      "......vars\n",
      "...layers\\lstm\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...metrics\\auc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      ".........3\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\precision\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\recall\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-06-21 03:21:52         1826\n",
      "metadata.json                                  2023-06-21 03:21:52           64\n",
      "variables.h5                                   2023-06-21 03:21:52       185968\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\lstm\n",
      "......vars\n",
      "...layers\\lstm\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...metrics\\auc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      ".........3\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\precision\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\recall\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-06-21 03:21:52         1827\n",
      "metadata.json                                  2023-06-21 03:21:52           64\n",
      "variables.h5                                   2023-06-21 03:21:52       578800\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\lstm\n",
      "......vars\n",
      "...layers\\lstm\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...metrics\\auc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      ".........3\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\precision\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\recall\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-06-21 03:21:52         1826\n",
      "metadata.json                                  2023-06-21 03:21:52           64\n",
      "variables.h5                                   2023-06-21 03:21:52       185968\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\lstm\n",
      "......vars\n",
      "...layers\\lstm\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...metrics\\auc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      ".........3\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\precision\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\recall\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-06-21 03:21:52         1827\n",
      "metadata.json                                  2023-06-21 03:21:52           64\n",
      "variables.h5                                   2023-06-21 03:21:52       578800\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\lstm\n",
      "......vars\n",
      "...layers\\lstm\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...metrics\\auc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      ".........3\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\precision\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\recall\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-06-21 03:21:52         1826\n",
      "metadata.json                                  2023-06-21 03:21:52           64\n",
      "variables.h5                                   2023-06-21 03:21:52       185968\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\lstm\n",
      "......vars\n",
      "...layers\\lstm\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...metrics\\auc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      ".........3\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\precision\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\recall\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-06-21 03:21:52         1827\n",
      "metadata.json                                  2023-06-21 03:21:52           64\n",
      "variables.h5                                   2023-06-21 03:21:52       578800\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\lstm\n",
      "......vars\n",
      "...layers\\lstm\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...metrics\\auc\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      ".........3\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\precision\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\recall\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 2s 4ms/step - loss: 0.2211 - auc: 0.9771 - Accuracy: 0.9431 - recall: 0.9431 - precision: 0.9431\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0577 - auc: 0.9978 - Accuracy: 0.9784 - recall: 0.9784 - precision: 0.9784\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0160 - auc: 0.9999 - Accuracy: 0.9961 - recall: 0.9961 - precision: 0.9961\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0073 - auc: 1.0000 - Accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0049 - auc: 1.0000 - Accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras is no longer supported, please use tf.keras instead.\n",
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 247, in grad_graph  *\n        out = self.model(shap_rAnD)\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 378, in custom_grad\n        out = op_handlers[type_name](self, op, *grads) # we cut off the shap_ prefex before the lookup\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 667, in handler\n        return linearity_with_excluded_handler(input_inds, explainer, op, *grads)\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 674, in linearity_with_excluded_handler\n        assert not explainer._variable_inputs(op)[i], str(i) + \"th input to \" + op.name + \" cannot vary!\"\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 224, in _variable_inputs\n        out[i] = t.name in self.between_tensors\n\n    AttributeError: Exception encountered when calling layer 'lstm_8' (type LSTM).\n    \n    'TFDeep' object has no attribute 'between_tensors'\n    \n    Call arguments received by layer 'lstm_8' (type LSTM):\n      • inputs=tf.Tensor(shape=(1020, 18, 12), dtype=float32)\n      • mask=None\n      • training=False\n      • initial_state=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gredi\\Desktop\\MADS\\696_Milestone2\\github\\milestoneII\\models\\lstm_rlieu.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gredi/Desktop/MADS/696_Milestone2/github/milestoneII/models/lstm_rlieu.ipynb#X15sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m#explainer=shap.DeepExplainer(model, X_train_shap)   #works!\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gredi/Desktop/MADS/696_Milestone2/github/milestoneII/models/lstm_rlieu.ipynb#X15sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m explainer\u001b[39m=\u001b[39mshap\u001b[39m.\u001b[39mDeepExplainer(model, X_train_shap)   \u001b[39m#works!\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gredi/Desktop/MADS/696_Milestone2/github/milestoneII/models/lstm_rlieu.ipynb#X15sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m values\u001b[39m=\u001b[39mexplainer\u001b[39m.\u001b[39;49mshap_values(np\u001b[39m.\u001b[39;49marray(X_test_shap))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py:124\u001b[0m, in \u001b[0;36mDeep.shap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshap_values\u001b[39m(\u001b[39mself\u001b[39m, X, ranked_outputs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, output_rank_order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m, check_additivity\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     91\u001b[0m     \u001b[39m\"\"\" Return approximate SHAP values for the model applied to the data given by X.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \n\u001b[0;32m     93\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m        were chosen as \"top\".\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexplainer\u001b[39m.\u001b[39;49mshap_values(X, ranked_outputs, output_rank_order, check_additivity\u001b[39m=\u001b[39;49mcheck_additivity)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:312\u001b[0m, in \u001b[0;36mTFDeep.shap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39m# run attribution computation graph\u001b[39;00m\n\u001b[0;32m    311\u001b[0m feature_ind \u001b[39m=\u001b[39m model_output_ranks[j,i]\n\u001b[1;32m--> 312\u001b[0m sample_phis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mphi_symbolic(feature_ind), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_inputs, joint_input)\n\u001b[0;32m    314\u001b[0m \u001b[39m# assign the attributions to the right part of the output arrays\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X)):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:372\u001b[0m, in \u001b[0;36mTFDeep.run\u001b[1;34m(self, out, model_inputs, X)\u001b[0m\n\u001b[0;32m    369\u001b[0m         tf_execute\u001b[39m.\u001b[39mrecord_gradient \u001b[39m=\u001b[39m tf_backprop\u001b[39m.\u001b[39mrecord_gradient\n\u001b[0;32m    371\u001b[0m     \u001b[39mreturn\u001b[39;00m final_out\n\u001b[1;32m--> 372\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute_with_overridden_gradients(anon)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:408\u001b[0m, in \u001b[0;36mTFDeep.execute_with_overridden_gradients\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[39m# define the computation graph for the attribution values using a custom gradient-like computation\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 408\u001b[0m     out \u001b[39m=\u001b[39m f()\n\u001b[0;32m    409\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     \u001b[39m# reinstate the backpropagatable check\u001b[39;00m\n\u001b[0;32m    411\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tf_gradients_impl, \u001b[39m\"\u001b[39m\u001b[39m_IsBackpropagatable\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:365\u001b[0m, in \u001b[0;36mTFDeep.run.<locals>.anon\u001b[1;34m()\u001b[0m\n\u001b[0;32m    363\u001b[0m     v \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(data, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_inputs[i]\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    364\u001b[0m     inputs\u001b[39m.\u001b[39mappend(v)\n\u001b[1;32m--> 365\u001b[0m final_out \u001b[39m=\u001b[39m out(inputs)\n\u001b[0;32m    366\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m     tf_execute\u001b[39m.\u001b[39mrecord_gradient \u001b[39m=\u001b[39m tf_backprop\u001b[39m.\u001b[39m_record_gradient\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file75ru8xbj.py:16\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__grad_graph\u001b[1;34m(shap_rAnD)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mwith\u001b[39;00m ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mGradientTape(watch_accessed_variables\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m     15\u001b[0m     ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tape)\u001b[39m.\u001b[39mwatch, (ag__\u001b[39m.\u001b[39mld(shap_rAnD),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 16\u001b[0m     out \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mmodel, (ag__\u001b[39m.\u001b[39mld(shap_rAnD),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     18\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mget_state\u001b[39m():\n\u001b[0;32m     19\u001b[0m         \u001b[39mreturn\u001b[39;00m (out,)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:378\u001b[0m, in \u001b[0;36mTFDeep.custom_grad\u001b[1;34m(self, op, *grads)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m\"\"\" Passes a gradient op creation request to the correct handler.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    377\u001b[0m type_name \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39mtype[\u001b[39m5\u001b[39m:] \u001b[39mif\u001b[39;00m op\u001b[39m.\u001b[39mtype\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mshap_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m op\u001b[39m.\u001b[39mtype\n\u001b[1;32m--> 378\u001b[0m out \u001b[39m=\u001b[39m op_handlers[type_name](\u001b[39mself\u001b[39;49m, op, \u001b[39m*\u001b[39;49mgrads) \u001b[39m# we cut off the shap_ prefex before the lookup\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:667\u001b[0m, in \u001b[0;36mlinearity_with_excluded.<locals>.handler\u001b[1;34m(explainer, op, *grads)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(explainer, op, \u001b[39m*\u001b[39mgrads):\n\u001b[1;32m--> 667\u001b[0m     \u001b[39mreturn\u001b[39;00m linearity_with_excluded_handler(input_inds, explainer, op, \u001b[39m*\u001b[39;49mgrads)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:674\u001b[0m, in \u001b[0;36mlinearity_with_excluded_handler\u001b[1;34m(input_inds, explainer, op, *grads)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(op\u001b[39m.\u001b[39minputs)):\n\u001b[0;32m    673\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39min\u001b[39;00m input_inds \u001b[39mor\u001b[39;00m i \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(op\u001b[39m.\u001b[39minputs) \u001b[39min\u001b[39;00m input_inds:\n\u001b[1;32m--> 674\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m explainer\u001b[39m.\u001b[39;49m_variable_inputs(op)[i], \u001b[39mstr\u001b[39m(i) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mth input to \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m op\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m cannot vary!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    675\u001b[0m \u001b[39mif\u001b[39;00m op\u001b[39m.\u001b[39mtype\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mshap_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    676\u001b[0m     op\u001b[39m.\u001b[39mtype \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39mtype[\u001b[39m5\u001b[39m:]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:224\u001b[0m, in \u001b[0;36mTFDeep._variable_inputs\u001b[1;34m(self, op)\u001b[0m\n\u001b[0;32m    222\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(op\u001b[39m.\u001b[39minputs), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool)\n\u001b[0;32m    223\u001b[0m     \u001b[39mfor\u001b[39;00m i,t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(op\u001b[39m.\u001b[39minputs):\n\u001b[1;32m--> 224\u001b[0m         out[i] \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbetween_tensors\n\u001b[0;32m    225\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vinputs[op] \u001b[39m=\u001b[39m out\n\u001b[0;32m    226\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vinputs[op]\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 247, in grad_graph  *\n        out = self.model(shap_rAnD)\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 378, in custom_grad\n        out = op_handlers[type_name](self, op, *grads) # we cut off the shap_ prefex before the lookup\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 667, in handler\n        return linearity_with_excluded_handler(input_inds, explainer, op, *grads)\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 674, in linearity_with_excluded_handler\n        assert not explainer._variable_inputs(op)[i], str(i) + \"th input to \" + op.name + \" cannot vary!\"\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 224, in _variable_inputs\n        out[i] = t.name in self.between_tensors\n\n    AttributeError: Exception encountered when calling layer 'lstm_8' (type LSTM).\n    \n    'TFDeep' object has no attribute 'between_tensors'\n    \n    Call arguments received by layer 'lstm_8' (type LSTM):\n      • inputs=tf.Tensor(shape=(1020, 18, 12), dtype=float32)\n      • mask=None\n      • training=False\n      • initial_state=None\n"
     ]
    }
   ],
   "source": [
    "##https://stackoverflow.com/questions/66814523/shap-deepexplainer-with-tensorflow-2-4-error?noredirect=1\n",
    "## this might be helpful your debugging!!!\n",
    "\n",
    "import shap\n",
    "import pickle\n",
    "# import tensorflow.compat.v1.keras.backend as K\n",
    "# import tensorflow as tf\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "# tf version is 2.3.1\n",
    "# kerase version is 2.4.0\n",
    "# Shap version is 0.36\n",
    "\n",
    "#tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "with open ('../result/result_dict_oecd.pkl','rb') as f:\n",
    "    result_dict_oecd=pickle.load(f)\n",
    "\n",
    "model=result_dict_oecd[0]['model']\n",
    "\n",
    "y_type = 'y_oecd'\n",
    "X_train, y_train, X_test, y_test = get_data(y_type, 5, selected_features)\n",
    "\n",
    "\n",
    "X_train_shap, y_train_shap = create_dataset(X_train, y_train, 18)\n",
    "X_test_shap, y_test_shap = create_dataset(X_train, y_train, 18)\n",
    "\n",
    "y_train_shap = to_categorical(y_train_shap, num_classes=2)\n",
    "y_test_shap = to_categorical(y_test_shap, num_classes=2)\n",
    "\n",
    "# X_train_shap=tf.convert_to_tensor(X_train_shap)\n",
    "# X_test_shap=tf.convert_to_tensor(X_test_shap)\n",
    "\n",
    "X_train_shap=np.array(X_train_shap)\n",
    "y_train_shap=np.array(y_train_shap)\n",
    "X_test_shap=np.array(X_test_shap)\n",
    "y_test_shap=np.array(y_test_shap)\n",
    "\n",
    "#type(X_train_shap)\n",
    "#X_train\n",
    "\n",
    "model.fit(X_train_shap, y_train_shap, batch_size=5, epochs=5)\n",
    "\n",
    "\n",
    "X_train_shap2=tf.convert_to_tensor(X_train_shap)\n",
    "X_test_shap2=tf.convert_to_tensor(X_test_shap)\n",
    "\n",
    "#explainer=shap.DeepExplainer(model, X_train_shap)   #works!\n",
    "\n",
    "explainer=shap.DeepExplainer(model, X_train_shap)   #works!\n",
    "\n",
    "values=explainer.shap_values(np.array(X_test_shap))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>time_steps</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hiddenlayer</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;keras.engine.sequential.Sequential object at ...</td>\n",
       "      <td>18</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>78.56%</td>\n",
       "      <td>59.52%</td>\n",
       "      <td>59.52%</td>\n",
       "      <td>59.52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;keras.engine.sequential.Sequential object at ...</td>\n",
       "      <td>18</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>79.56%</td>\n",
       "      <td>57.14%</td>\n",
       "      <td>57.14%</td>\n",
       "      <td>57.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;keras.engine.sequential.Sequential object at ...</td>\n",
       "      <td>18</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>85.98%</td>\n",
       "      <td>78.57%</td>\n",
       "      <td>78.57%</td>\n",
       "      <td>78.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;keras.engine.sequential.Sequential object at ...</td>\n",
       "      <td>18</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>79.51%</td>\n",
       "      <td>64.29%</td>\n",
       "      <td>64.29%</td>\n",
       "      <td>64.29%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;keras.engine.sequential.Sequential object at ...</td>\n",
       "      <td>24</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>89.37%</td>\n",
       "      <td>75.00%</td>\n",
       "      <td>75.00%</td>\n",
       "      <td>75.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;keras.engine.sequential.Sequential object at ...</td>\n",
       "      <td>24</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>71.76%</td>\n",
       "      <td>61.11%</td>\n",
       "      <td>61.11%</td>\n",
       "      <td>61.11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;keras.engine.sequential.Sequential object at ...</td>\n",
       "      <td>24</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>79.67%</td>\n",
       "      <td>61.11%</td>\n",
       "      <td>61.11%</td>\n",
       "      <td>61.11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;keras.engine.sequential.Sequential object at ...</td>\n",
       "      <td>24</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>76.02%</td>\n",
       "      <td>61.11%</td>\n",
       "      <td>61.11%</td>\n",
       "      <td>61.11%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  time_steps  num_epochs  \\\n",
       "0  <keras.engine.sequential.Sequential object at ...          18         300   \n",
       "1  <keras.engine.sequential.Sequential object at ...          18         300   \n",
       "2  <keras.engine.sequential.Sequential object at ...          18         500   \n",
       "3  <keras.engine.sequential.Sequential object at ...          18         500   \n",
       "4  <keras.engine.sequential.Sequential object at ...          24         300   \n",
       "5  <keras.engine.sequential.Sequential object at ...          24         300   \n",
       "6  <keras.engine.sequential.Sequential object at ...          24         500   \n",
       "7  <keras.engine.sequential.Sequential object at ...          24         500   \n",
       "\n",
       "   batch_size  hiddenlayer     auc     acc  recall precision  \n",
       "0           5           50  78.56%  59.52%  59.52%    59.52%  \n",
       "1           5          100  79.56%  57.14%  57.14%    57.14%  \n",
       "2           5           50  85.98%  78.57%  78.57%    78.57%  \n",
       "3           5          100  79.51%  64.29%  64.29%    64.29%  \n",
       "4           5           50  89.37%  75.00%  75.00%    75.00%  \n",
       "5           5          100  71.76%  61.11%  61.11%    61.11%  \n",
       "6           5           50  79.67%  61.11%  61.11%    61.11%  \n",
       "7           5          100  76.02%  61.11%  61.11%    61.11%  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result_dict_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor 'shap_rAnD:0' shape=(1020, 18, 12) dtype=float32>]. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 247, in grad_graph  *\n        out = self.model(shap_rAnD)\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 378, in custom_grad\n        out = op_handlers[type_name](self, op, *grads) # we cut off the shap_ prefex before the lookup\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 667, in handler\n        return linearity_with_excluded_handler(input_inds, explainer, op, *grads)\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 674, in linearity_with_excluded_handler\n        assert not explainer._variable_inputs(op)[i], str(i) + \"th input to \" + op.name + \" cannot vary!\"\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 224, in _variable_inputs\n        out[i] = t.name in self.between_tensors\n\n    AttributeError: Exception encountered when calling layer 'lstm' (type LSTM).\n    \n    'TFDeep' object has no attribute 'between_tensors'\n    \n    Call arguments received by layer 'lstm' (type LSTM):\n      • inputs=tf.Tensor(shape=(1020, 18, 12), dtype=float32)\n      • mask=None\n      • training=False\n      • initial_state=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gredi\\Desktop\\MADS\\696_Milestone2\\github\\milestoneII\\models\\lstm_rlieu.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gredi/Desktop/MADS/696_Milestone2/github/milestoneII/models/lstm_rlieu.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m values\u001b[39m=\u001b[39mexplainer\u001b[39m.\u001b[39;49mshap_values(np\u001b[39m.\u001b[39;49marray(X_test_shap))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py:124\u001b[0m, in \u001b[0;36mDeep.shap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshap_values\u001b[39m(\u001b[39mself\u001b[39m, X, ranked_outputs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, output_rank_order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m, check_additivity\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     91\u001b[0m     \u001b[39m\"\"\" Return approximate SHAP values for the model applied to the data given by X.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \n\u001b[0;32m     93\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m        were chosen as \"top\".\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexplainer\u001b[39m.\u001b[39;49mshap_values(X, ranked_outputs, output_rank_order, check_additivity\u001b[39m=\u001b[39;49mcheck_additivity)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:312\u001b[0m, in \u001b[0;36mTFDeep.shap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39m# run attribution computation graph\u001b[39;00m\n\u001b[0;32m    311\u001b[0m feature_ind \u001b[39m=\u001b[39m model_output_ranks[j,i]\n\u001b[1;32m--> 312\u001b[0m sample_phis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mphi_symbolic(feature_ind), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_inputs, joint_input)\n\u001b[0;32m    314\u001b[0m \u001b[39m# assign the attributions to the right part of the output arrays\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X)):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:372\u001b[0m, in \u001b[0;36mTFDeep.run\u001b[1;34m(self, out, model_inputs, X)\u001b[0m\n\u001b[0;32m    369\u001b[0m         tf_execute\u001b[39m.\u001b[39mrecord_gradient \u001b[39m=\u001b[39m tf_backprop\u001b[39m.\u001b[39mrecord_gradient\n\u001b[0;32m    371\u001b[0m     \u001b[39mreturn\u001b[39;00m final_out\n\u001b[1;32m--> 372\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute_with_overridden_gradients(anon)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:408\u001b[0m, in \u001b[0;36mTFDeep.execute_with_overridden_gradients\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[39m# define the computation graph for the attribution values using a custom gradient-like computation\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 408\u001b[0m     out \u001b[39m=\u001b[39m f()\n\u001b[0;32m    409\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     \u001b[39m# reinstate the backpropagatable check\u001b[39;00m\n\u001b[0;32m    411\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tf_gradients_impl, \u001b[39m\"\u001b[39m\u001b[39m_IsBackpropagatable\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:365\u001b[0m, in \u001b[0;36mTFDeep.run.<locals>.anon\u001b[1;34m()\u001b[0m\n\u001b[0;32m    363\u001b[0m     v \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(data, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_inputs[i]\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    364\u001b[0m     inputs\u001b[39m.\u001b[39mappend(v)\n\u001b[1;32m--> 365\u001b[0m final_out \u001b[39m=\u001b[39m out(inputs)\n\u001b[0;32m    366\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m     tf_execute\u001b[39m.\u001b[39mrecord_gradient \u001b[39m=\u001b[39m tf_backprop\u001b[39m.\u001b[39m_record_gradient\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file0_nkl5dq.py:16\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__grad_graph\u001b[1;34m(shap_rAnD)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mwith\u001b[39;00m ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mGradientTape(watch_accessed_variables\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m     15\u001b[0m     ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tape)\u001b[39m.\u001b[39mwatch, (ag__\u001b[39m.\u001b[39mld(shap_rAnD),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 16\u001b[0m     out \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mmodel, (ag__\u001b[39m.\u001b[39mld(shap_rAnD),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     18\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mget_state\u001b[39m():\n\u001b[0;32m     19\u001b[0m         \u001b[39mreturn\u001b[39;00m (out,)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:378\u001b[0m, in \u001b[0;36mTFDeep.custom_grad\u001b[1;34m(self, op, *grads)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m\"\"\" Passes a gradient op creation request to the correct handler.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    377\u001b[0m type_name \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39mtype[\u001b[39m5\u001b[39m:] \u001b[39mif\u001b[39;00m op\u001b[39m.\u001b[39mtype\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mshap_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m op\u001b[39m.\u001b[39mtype\n\u001b[1;32m--> 378\u001b[0m out \u001b[39m=\u001b[39m op_handlers[type_name](\u001b[39mself\u001b[39;49m, op, \u001b[39m*\u001b[39;49mgrads) \u001b[39m# we cut off the shap_ prefex before the lookup\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:667\u001b[0m, in \u001b[0;36mlinearity_with_excluded.<locals>.handler\u001b[1;34m(explainer, op, *grads)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(explainer, op, \u001b[39m*\u001b[39mgrads):\n\u001b[1;32m--> 667\u001b[0m     \u001b[39mreturn\u001b[39;00m linearity_with_excluded_handler(input_inds, explainer, op, \u001b[39m*\u001b[39;49mgrads)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:674\u001b[0m, in \u001b[0;36mlinearity_with_excluded_handler\u001b[1;34m(input_inds, explainer, op, *grads)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(op\u001b[39m.\u001b[39minputs)):\n\u001b[0;32m    673\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39min\u001b[39;00m input_inds \u001b[39mor\u001b[39;00m i \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(op\u001b[39m.\u001b[39minputs) \u001b[39min\u001b[39;00m input_inds:\n\u001b[1;32m--> 674\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m explainer\u001b[39m.\u001b[39;49m_variable_inputs(op)[i], \u001b[39mstr\u001b[39m(i) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mth input to \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m op\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m cannot vary!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    675\u001b[0m \u001b[39mif\u001b[39;00m op\u001b[39m.\u001b[39mtype\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mshap_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    676\u001b[0m     op\u001b[39m.\u001b[39mtype \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39mtype[\u001b[39m5\u001b[39m:]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:224\u001b[0m, in \u001b[0;36mTFDeep._variable_inputs\u001b[1;34m(self, op)\u001b[0m\n\u001b[0;32m    222\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(op\u001b[39m.\u001b[39minputs), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool)\n\u001b[0;32m    223\u001b[0m     \u001b[39mfor\u001b[39;00m i,t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(op\u001b[39m.\u001b[39minputs):\n\u001b[1;32m--> 224\u001b[0m         out[i] \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbetween_tensors\n\u001b[0;32m    225\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vinputs[op] \u001b[39m=\u001b[39m out\n\u001b[0;32m    226\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vinputs[op]\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 247, in grad_graph  *\n        out = self.model(shap_rAnD)\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 378, in custom_grad\n        out = op_handlers[type_name](self, op, *grads) # we cut off the shap_ prefex before the lookup\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 667, in handler\n        return linearity_with_excluded_handler(input_inds, explainer, op, *grads)\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 674, in linearity_with_excluded_handler\n        assert not explainer._variable_inputs(op)[i], str(i) + \"th input to \" + op.name + \" cannot vary!\"\n    File \"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 224, in _variable_inputs\n        out[i] = t.name in self.between_tensors\n\n    AttributeError: Exception encountered when calling layer 'lstm' (type LSTM).\n    \n    'TFDeep' object has no attribute 'between_tensors'\n    \n    Call arguments received by layer 'lstm' (type LSTM):\n      • inputs=tf.Tensor(shape=(1020, 18, 12), dtype=float32)\n      • mask=None\n      • training=False\n      • initial_state=None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
